{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/emrekaany/news-categorization-model?scriptVersionId=236203144\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"274af3b0","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-04-26T08:49:46.967046Z","iopub.status.busy":"2025-04-26T08:49:46.966727Z","iopub.status.idle":"2025-04-26T08:49:50.761258Z","shell.execute_reply":"2025-04-26T08:49:50.759999Z"},"papermill":{"duration":3.799965,"end_time":"2025-04-26T08:49:50.762986","exception":false,"start_time":"2025-04-26T08:49:46.963021","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","--- Model Evaluation ---\n","Test Set Accuracy: 0.3704\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","         buy       0.44      0.36      0.40        11\n","        hold       0.67      0.55      0.60        11\n","        sell       0.19      0.27      0.22        11\n","  strong buy       0.46      0.55      0.50        11\n"," strong sell       0.14      0.10      0.12        10\n","\n","    accuracy                           0.37        54\n","   macro avg       0.38      0.37      0.37        54\n","weighted avg       0.39      0.37      0.37        54\n","\n","\n","Confusion Matrix:\n","             buy  hold  sell  strong buy  strong sell\n","buy            4     1     2           4            0\n","hold           1     6     3           1            0\n","sell           0     1     3           1            6\n","strong buy     4     0     1           6            0\n","strong sell    0     1     7           1            1\n","------------------------\n","\n","Trained model pipeline saved to: sentiment_model.joblib\n","\n","--- Example Prediction ---\n","\n","Input Text: 'This stock is poised for a major breakout, expecting significant gains.'\n","Predicted Sentiment: -> sell <-\n","\n","Input Text: 'Market conditions are uncertain, maintaining current position seems prudent.'\n","Predicted Sentiment: -> hold <-\n","\n","Input Text: 'Earnings disappointed, recommend reducing exposure.'\n","Predicted Sentiment: -> sell <-\n"]}],"source":["\n","import pandas as pd\n","import joblib # Used for saving/loading sklearn models efficiently\n","import logging\n","import os\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.pipeline import Pipeline # To chain vectorizer and classifier\n","from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n","from sklearn.preprocessing import LabelEncoder # To convert string labels to numbers\n","\n","# --- Configuration ---\n","# Updated dataset path for Kaggle environment\n","DATASET_PATH = '/kaggle/input/financial-comments-for-sentiment-analysis/financial_sentiment_dataset.csv'\n","MODEL_SAVE_PATH = 'sentiment_model.joblib'\n","# Removed VECTORIZER_SAVE_PATH as it's saved within the pipeline\n","LABEL_ENCODER_SAVE_PATH = 'label_encoder.joblib' # Define path for label encoder\n","TEST_SET_SIZE = 0.2 # 20% of data for testing\n","RANDOM_STATE = 42 # For reproducible train/test splits\n","\n","# Configure logging\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","\n","# --- Main Training Function ---\n","def train_sentiment_model():\n","    \"\"\"Loads data, preprocesses, trains, evaluates, and saves the model.\"\"\"\n","\n","    logging.info(\"--- Starting Sentiment Model Training ---\")\n","\n","    # 1. Load Data\n","    logging.info(f\"Loading dataset from: {DATASET_PATH}\")\n","    if not os.path.exists(DATASET_PATH):\n","        logging.error(f\"Error: Dataset file not found at '{DATASET_PATH}'.\")\n","        print(f\"\\nPlease make sure '{DATASET_PATH}' exists.\")\n","        print(\"Check the input path, especially in environments like Kaggle.\")\n","        return\n","    try:\n","        df = pd.read_csv(DATASET_PATH)\n","        # Basic validation\n","        if 'text' not in df.columns or 'label' not in df.columns:\n","             logging.error(\"Error: Dataset must contain 'text' and 'label' columns.\")\n","             print(\"\\nError: The CSV file must have 'text' and 'label' columns.\")\n","             return\n","        # Handle potential missing values (simple drop)\n","        df.dropna(subset=['text', 'label'], inplace=True)\n","        if df.empty:\n","            logging.error(\"Error: Dataset is empty after handling missing values.\")\n","            print(\"\\nError: The dataset is empty. Please check the CSV file.\")\n","            return\n","        logging.info(f\"Dataset loaded successfully. Shape: {df.shape}\")\n","        logging.info(f\"Label distribution:\\n{df['label'].value_counts()}\")\n","    except Exception as e:\n","        logging.error(f\"Error loading or processing dataset: {e}\")\n","        print(f\"\\nAn error occurred while loading the dataset: {e}\")\n","        return\n","\n","    # 2. Preprocessing & Feature Engineering\n","    logging.info(\"Preprocessing data...\")\n","    X = df['text'] # Features (input text)\n","    y_raw = df['label'] # Target labels (strings)\n","\n","    # Encode string labels into numerical format\n","    label_encoder = LabelEncoder()\n","    y = label_encoder.fit_transform(y_raw)\n","    logging.info(f\"Labels encoded. Mapping: {dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))}\")\n","\n","    # Save the label encoder for later decoding predictions\n","    try:\n","        joblib.dump(label_encoder, LABEL_ENCODER_SAVE_PATH)\n","        logging.info(f\"Label encoder saved to '{LABEL_ENCODER_SAVE_PATH}'\")\n","    except Exception as e:\n","        logging.error(f\"Error saving label encoder: {e}\")\n","        print(f\"\\nWarning: Could not save the label encoder: {e}\")\n","\n","\n","    # 3. Split Data into Training and Testing sets\n","    logging.info(f\"Splitting data into training and testing sets (Test size: {TEST_SET_SIZE})...\")\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, y,\n","        test_size=TEST_SET_SIZE,\n","        random_state=RANDOM_STATE,\n","        stratify=y # Ensure label distribution is similar in train/test sets\n","    )\n","    logging.info(f\"Training set size: {len(X_train)}, Test set size: {len(X_test)}\")\n","\n","    # 4. Define Model Pipeline\n","    # Pipeline chains the vectorizer and the classifier together.\n","    # This ensures that the same vectorization is applied during training and prediction.\n","    logging.info(\"Defining model pipeline (TF-IDF Vectorizer + Logistic Regression)...\")\n","    pipeline = Pipeline([\n","        ('tfidf', TfidfVectorizer(stop_words='english', # Remove common English words\n","                                  ngram_range=(1, 2), # Consider single words and pairs\n","                                  max_features=5000)), # Limit number of features\n","        ('clf', LogisticRegression(solver='liblinear', # Good solver for smaller datasets\n","                                   multi_class='ovr', # One-vs-Rest for multi-class\n","                                   random_state=RANDOM_STATE))\n","    ])\n","    # Note: You can experiment with different vectorizers (e.g., CountVectorizer)\n","    # and classifiers (e.g., MultinomialNB, SVC, RandomForestClassifier).\n","\n","    # 5. Train the Model\n","    logging.info(\"Training the model...\")\n","    try:\n","        pipeline.fit(X_train, y_train)\n","        logging.info(\"Model training completed.\")\n","    except Exception as e:\n","        logging.error(f\"An error occurred during model training: {e}\")\n","        print(f\"\\nModel training failed: {e}\")\n","        return\n","\n","    # 6. Evaluate the Model\n","    logging.info(\"Evaluating the model on the test set...\")\n","    try:\n","        y_pred = pipeline.predict(X_test)\n","\n","        # Decode numeric predictions back to original labels for reporting\n","        y_pred_labels = label_encoder.inverse_transform(y_pred)\n","        # y_test_labels = label_encoder.inverse_transform(y_test) # Not strictly needed for report\n","        class_labels = label_encoder.classes_ # Get the actual label names\n","\n","        accuracy = accuracy_score(y_test, y_pred)\n","        # Added zero_division=0 to handle cases where a class might not have predictions in the test set\n","        report = classification_report(y_test, y_pred, target_names=class_labels, zero_division=0)\n","        conf_matrix = confusion_matrix(y_test, y_pred, labels=label_encoder.transform(class_labels)) # Ensure consistent label order\n","\n","        logging.info(f\"Test Set Accuracy: {accuracy:.4f}\")\n","        logging.info(f\"Classification Report:\\n{report}\")\n","        logging.info(f\"Confusion Matrix:\\n{conf_matrix}\")\n","\n","        print(\"\\n--- Model Evaluation ---\")\n","        print(f\"Test Set Accuracy: {accuracy:.4f}\")\n","        print(\"\\nClassification Report:\")\n","        print(report)\n","        print(\"\\nConfusion Matrix:\")\n","        # Print confusion matrix with labels for clarity\n","        print(pd.DataFrame(conf_matrix, index=class_labels, columns=class_labels))\n","        print(\"------------------------\")\n","    except Exception as e:\n","         logging.error(f\"An error occurred during model evaluation: {e}\")\n","         print(f\"\\nModel evaluation failed: {e}\")\n","         # Continue to saving attempt even if evaluation fails\n","\n","    # 7. Save the Trained Model Pipeline\n","    logging.info(f\"Saving the trained pipeline to {MODEL_SAVE_PATH}...\")\n","    try:\n","        # The pipeline object contains both the fitted vectorizer and the fitted classifier\n","        joblib.dump(pipeline, MODEL_SAVE_PATH)\n","        logging.info(\"Pipeline saved successfully.\")\n","        print(f\"\\nTrained model pipeline saved to: {MODEL_SAVE_PATH}\")\n","    except Exception as e:\n","        logging.error(f\"Error saving the model pipeline: {e}\")\n","        print(f\"\\nError saving the model: {e}\")\n","\n","    logging.info(\"--- Sentiment Model Training Finished ---\")\n","\n","# --- Prediction Function ---\n","def predict_sentiment(text_input):\n","    \"\"\"Loads the saved model and predicts sentiment for new text.\"\"\"\n","    logging.info(f\"--- Predicting Sentiment for: '{text_input}' ---\")\n","\n","    # Check if model and label encoder files exist\n","    if not os.path.exists(MODEL_SAVE_PATH) or not os.path.exists(LABEL_ENCODER_SAVE_PATH):\n","        logging.error(\"Model or label encoder file not found. Please train the model first.\")\n","        print(f\"\\nError: Model ({MODEL_SAVE_PATH}) or label encoder ({LABEL_ENCODER_SAVE_PATH}) not found. Run the training script first.\")\n","        return None\n","\n","    try:\n","        # Load the pipeline (contains vectorizer and classifier)\n","        pipeline = joblib.load(MODEL_SAVE_PATH)\n","        # Load the label encoder\n","        label_encoder = joblib.load(LABEL_ENCODER_SAVE_PATH)\n","        logging.info(\"Model pipeline and label encoder loaded successfully.\")\n","\n","        # The pipeline handles vectorization automatically\n","        # Input must be iterable (like a list), even for a single prediction\n","        prediction_numeric = pipeline.predict([text_input])\n","\n","        # Decode the numeric prediction back to the original string label\n","        predicted_label = label_encoder.inverse_transform(prediction_numeric)\n","\n","        logging.info(f\"Input: '{text_input}' => Predicted Label: '{predicted_label[0]}'\")\n","        print(f\"\\nInput Text: '{text_input}'\")\n","        print(f\"Predicted Sentiment: -> {predicted_label[0]} <-\")\n","        return predicted_label[0]\n","\n","    except Exception as e:\n","        logging.error(f\"Error during prediction: {e}\")\n","        print(f\"\\nAn error occurred during prediction: {e}\")\n","        return None\n","\n","\n","# --- Main Execution ---\n","if __name__ == \"__main__\":\n","    # 1. Train the model (if the script is run directly)\n","    train_sentiment_model()\n","\n","    # 2. Example Prediction (after training)\n","    print(\"\\n--- Example Prediction ---\")\n","    # Check if model exists before attempting prediction\n","    if os.path.exists(MODEL_SAVE_PATH) and os.path.exists(LABEL_ENCODER_SAVE_PATH):\n","        example_text_1 = \"This stock is poised for a major breakout, expecting significant gains.\"\n","        predict_sentiment(example_text_1)\n","\n","        example_text_2 = \"Market conditions are uncertain, maintaining current position seems prudent.\"\n","        predict_sentiment(example_text_2)\n","\n","        example_text_3 = \"Earnings disappointed, recommend reducing exposure.\"\n","        predict_sentiment(example_text_3)\n","    else:\n","        print(\"\\nSkipping example prediction as the model or label encoder file was not created (likely due to training errors).\")\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":7255304,"sourceId":11572426,"sourceType":"datasetVersion"}],"dockerImageVersionId":31012,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"papermill":{"default_parameters":{},"duration":9.327324,"end_time":"2025-04-26T08:49:51.486835","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-04-26T08:49:42.159511","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}