{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/emrekaany/data-generating-with-gemini-for-sentiment-model?scriptVersionId=236212353\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"b7884955","metadata":{"execution":{"iopub.execute_input":"2025-04-26T09:51:29.097472Z","iopub.status.busy":"2025-04-26T09:51:29.097214Z","iopub.status.idle":"2025-04-26T09:51:33.728118Z","shell.execute_reply":"2025-04-26T09:51:33.726979Z"},"papermill":{"duration":4.636091,"end_time":"2025-04-26T09:51:33.729871","exception":false,"start_time":"2025-04-26T09:51:29.09378","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\r\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\r\n","Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\r\n","Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (1.34.1)\r\n","Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.160.0)\r\n","Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.27.0)\r\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (3.20.3)\r\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.3)\r\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\r\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.1)\r\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\r\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\r\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\r\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\r\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\r\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.67.0)\r\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\r\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\r\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\r\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\r\n","Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.3.8)\r\n","Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.2.4)\r\n","Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (0.1.1)\r\n","Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2025.1.0)\r\n","Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2022.1.0)\r\n","Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2.4.1)\r\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n","Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\r\n","Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\r\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\r\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\r\n","Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.1)\r\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.0)\r\n","Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\r\n","Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.48.2)\r\n","Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\r\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\r\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\r\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (3.10)\r\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\r\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\r\n","Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2024.2.0)\r\n","Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2022.1.0)\r\n","Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas) (1.2.0)\r\n","Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas) (2024.2.0)\r\n","Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas) (2024.2.0)\r\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install google-generativeai pandas"]},{"cell_type":"code","execution_count":2,"id":"f948a325","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-04-26T09:51:33.736111Z","iopub.status.busy":"2025-04-26T09:51:33.73574Z","iopub.status.idle":"2025-04-26T09:51:37.094422Z","shell.execute_reply":"2025-04-26T09:51:37.093133Z"},"papermill":{"duration":3.363521,"end_time":"2025-04-26T09:51:37.096067","exception":false,"start_time":"2025-04-26T09:51:33.732546","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\r\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install tqdm"]},{"cell_type":"code","execution_count":3,"id":"3fa5d12e","metadata":{"execution":{"iopub.execute_input":"2025-04-26T09:51:37.102582Z","iopub.status.busy":"2025-04-26T09:51:37.102291Z","iopub.status.idle":"2025-04-26T09:52:13.116874Z","shell.execute_reply":"2025-04-26T09:52:13.115949Z"},"papermill":{"duration":36.01969,"end_time":"2025-04-26T09:52:13.118355","exception":false,"start_time":"2025-04-26T09:51:37.098665","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["Generating Long Comments: 100%|██████████| 5/5 [00:32<00:00,  6.40s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","Merged dataset saved to merged_financial_sentiment_dataset.csv\n","Total rows: 367\n","\n","Sample data (last 5 rows might include new long comments):\n","                                                  text        label\n","362  Epsilon Inc.'s recent product recall, coupled ...  strong sell\n","363  Zeta Holdings’ failure to meet its Q4 revenue ...  strong sell\n","364  The emergence of a disruptive technology from ...  strong sell\n","365  Our analysis indicates that Omega Pharmaceutic...  strong sell\n","366  Based on our proprietary valuation model, whic...  strong sell\n","\n","Label distribution (merged):\n","label\n","sell           76\n","strong buy     74\n","buy            74\n","hold           73\n","strong sell    70\n","Name: count, dtype: int64\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Generates a financial sentiment dataset using the Gemini API\n","and merges it with an existing dataset.\n","\n","This script prompts a generative model (like Gemini) to create longer text examples\n","(aiming for >50 words) for predefined financial sentiment labels and merges them\n","with data from an existing CSV file before saving.\n","\"\"\"\n","\n","import google.generativeai as genai\n","import pandas as pd\n","import os\n","import time\n","import logging\n","from tqdm import tqdm  # Optional: for progress bar (pip install tqdm)\n","from kaggle_secrets import UserSecretsClient\n","\n","\n","# --- Configuration ---\n","# Define the sentiment labels you want to generate data for\n","SENTIMENT_LABELS = [\"strong buy\", \"buy\", \"hold\", \"sell\", \"strong sell\"]\n","\n","# Number of LONG examples to generate for each label\n","EXAMPLES_PER_LABEL = 10 # Reduce this number as long comments take more time/tokens\n","\n","# Model name (check availability in your region/API access)\n","MODEL_NAME = 'gemini-1.5-flash' # Or 'gemini-pro', 'gemini-1.0-pro', etc.\n","\n","# --- File Paths ---\n","# Path to the existing dataset generated previously\n","EXISTING_DATA_FILE = 'merged_financial_sentiment_dataset.csv'\n","# Output filename for the MERGED dataset\n","OUTPUT_CSV_FILE = 'merged_financial_sentiment_dataset.csv'\n","\n","# Delay between API calls (in seconds) to respect rate limits if necessary\n","API_CALL_DELAY = 2 # Increase delay slightly for potentially longer generation times\n","\n","user_secrets = UserSecretsClient()\n","secret_value_0 = user_secrets.get_secret(\"GEMINI_API_KEY\")\n","api_key = secret_value_0  \n","\n","# Configure logging\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","\n","# --- Helper Function (Modified for Longer Comments) ---\n","def generate_long_examples_for_label(model, label, num_examples):\n","    \"\"\"\n","    Generates LONGER text examples for a given sentiment label using the generative model.\n","\n","    Args:\n","        model: The configured generative model instance.\n","        label (str): The sentiment label (e.g., \"buy\", \"hold\").\n","        num_examples (int): The number of examples to request.\n","\n","    Returns:\n","        list: A list of generated text examples (strings), or None if generation fails.\n","    \"\"\"\n","    # Modified prompt to ask for longer comments (aiming for > 50 words)\n","    prompt = f\"\"\"\n","    Generate {num_examples} diverse and realistic **detailed comments or short paragraphs**, each ideally **between 50 and 100 words**, that clearly express a '{label}' sentiment towards a stock, investment, or financial asset.\n","    Focus on language typically used by financial analysts, traders, or investors in reports, detailed commentary, or investment forums, going beyond simple short phrases.\n","    Provide reasoning or context within the comment where appropriate for the sentiment.\n","    Each comment/paragraph should be separated by a blank line. Do not include bullet points or numbering before each comment.\n","\n","    Example structure for '{label}':\n","    - If '{label}' is 'strong buy': Start with a strong positive assertion, mention key drivers like earnings growth, market position, or valuation, and conclude with a confident outlook. Aim for 50+ words.\n","    - If '{label}' is 'hold': Express a neutral or cautious stance, perhaps citing balanced risk/reward, waiting for specific catalysts or data, or fair valuation. Explain why neither buying more nor selling is advised currently. Aim for 50+ words.\n","    - If '{label}' is 'sell': Clearly state the negative outlook, provide reasons such as declining fundamentals, competitive threats, overvaluation, or macroeconomic headwinds, and suggest exiting the position. Aim for 50+ words.\n","\n","    Generate {num_examples} detailed examples for '{label}':\n","    \"\"\"\n","\n","    try:\n","        logging.info(f\"Generating {num_examples} LONG examples for label: '{label}'...\")\n","        # Adjust generation config if needed (e.g., potentially increase max_output_tokens)\n","        response = model.generate_content(\n","            prompt,\n","            generation_config=genai.types.GenerationConfig(\n","                temperature=0.75, # Slightly higher temp might help with longer, creative text\n","                # max_output_tokens=2048 # Increase if needed for longer responses\n","            ),\n","            # safety_settings=[ ... ] # Add safety settings if needed\n","        )\n","\n","        # Check if the response has text content\n","        if hasattr(response, 'text'):\n","            generated_text = response.text\n","            # Split by double newline, assuming paragraphs are separated by blank lines\n","            # Also handle single newlines just in case. Trim whitespace.\n","            examples = [p.strip() for p in generated_text.split('\\n\\n') if p.strip()]\n","            if not examples or len(examples) < num_examples / 2: # Basic check if splitting failed\n","                 # Fallback split by single newline if double didn't work well\n","                 examples = [line.strip() for line in generated_text.split('\\n') if line.strip()]\n","\n","            # Basic length check (optional filter)\n","            # examples = [ex for ex in examples if len(ex.split()) > 40] # Keep if > 40 words\n","\n","            logging.info(f\"Successfully generated {len(examples)} raw examples for '{label}'.\")\n","            return examples\n","        elif response.prompt_feedback.block_reason:\n","             logging.error(f\"API call blocked for label '{label}'. Reason: {response.prompt_feedback.block_reason}\")\n","             return None\n","        else:\n","            logging.warning(f\"Received an empty or unexpected response for label '{label}'. Response parts: {response.parts}\")\n","            return None\n","\n","    except Exception as e:\n","        logging.error(f\"An error occurred while generating examples for label '{label}': {e}\")\n","        return None\n","\n","\n","logging.info(\"--- Starting Financial Sentiment Dataset Generation (Long Comments & Merge) ---\")\n","\n","# --- Load Existing Data ---\n","old_df = pd.read_csv(\"/kaggle/input/financial-comments-for-sentiment-analysis/merged_financial_sentiment_dataset.csv\") # Initialize empty DataFrame\n","if os.path.exists(EXISTING_DATA_FILE):\n","    try:\n","        logging.info(f\"Loading existing dataset from: {EXISTING_DATA_FILE}\")\n","        old_df = pd.read_csv(EXISTING_DATA_FILE)\n","        # Basic validation\n","        if 'text' not in old_df.columns or 'label' not in old_df.columns:\n","            logging.warning(f\"Existing dataset '{EXISTING_DATA_FILE}' is missing 'text' or 'label' columns. It will be ignored.\")\n","            old_df = pd.DataFrame() # Reset if columns are wrong\n","        else:\n","             logging.info(f\"Loaded {len(old_df)} records from existing dataset.\")\n","             # Optional: Drop duplicates from old data before merging\n","             old_df.drop_duplicates(subset=['text', 'label'], inplace=True)\n","             logging.info(f\"{len(old_df)} unique records remaining after checking old data.\")\n","\n","    except Exception as e:\n","        logging.error(f\"Error loading existing dataset '{EXISTING_DATA_FILE}': {e}. Proceeding without it.\")\n","        old_df = pd.DataFrame() # Ensure it's empty if loading fails\n","else:\n","    logging.warning(f\"Existing dataset file '{EXISTING_DATA_FILE}' not found. Only new data will be generated.\")\n","\n","# --- Configure API ---\n","if not api_key:\n","    # ** CRITICAL SECURITY WARNING **\n","    logging.error(\"CRITICAL: API key is missing or empty. Using hardcoded keys is insecure.\")\n","    print(\"\\nCRITICAL SECURITY WARNING:\")\n","    print(\"No API key found or provided key is empty.\")\n","    print(\"Using hardcoded API keys is a major security risk.\")\n","    print(\"Please configure the API key securely (e.g., using environment variables) and restart.\")\n","    # Optionally, you might want to exit here if the key is truly missing\n","    # return\n","    # For demonstration, allowing continuation if key was hardcoded above\n","    # but strongly advising against it.\n","\n","try:\n","    genai.configure(api_key=api_key)\n","    logging.info(\"Gemini API key configured. (WARNING: Ensure key is handled securely)\")\n","except Exception as e:\n","    logging.error(f\"Error configuring Gemini API: {e}\")\n","    \n","\n","# --- Initialize the Generative Model ---\n","try:\n","    model = genai.GenerativeModel(MODEL_NAME)\n","    logging.info(f\"Generative model '{MODEL_NAME}' initialized.\")\n","except Exception as e:\n","    logging.error(f\"Error initializing model '{MODEL_NAME}': {e}\")\n","    print(f\"\\nCould not initialize model '{MODEL_NAME}'. Check if the model name is correct and available.\")\n","    \n","\n","# --- Generate New LONG Data ---\n","new_long_comments_data = []\n","total_labels = len(SENTIMENT_LABELS)\n","logging.info(f\"Generating {EXAMPLES_PER_LABEL} LONG comments for each of {total_labels} labels: {', '.join(SENTIMENT_LABELS)}\")\n","\n","label_iterator = tqdm(SENTIMENT_LABELS, desc=\"Generating Long Comments\") if 'tqdm' in globals() else SENTIMENT_LABELS\n","\n","for i, label in enumerate(label_iterator):\n","    # Use the modified function for long examples\n","    generated_examples = generate_long_examples_for_label(model, label, EXAMPLES_PER_LABEL)\n","\n","    if generated_examples:\n","        for example in generated_examples:\n","            # Optional: Add another length filter here if needed\n","            # if len(example.split()) > 50:\n","            new_long_comments_data.append({'text': example, 'label': label})\n","    else:\n","        logging.warning(f\"Skipping label '{label}' for long comments due to generation failure or empty response.\")\n","\n","    # Add delay between API calls\n","    if i < total_labels - 1:\n","        logging.debug(f\"Waiting for {API_CALL_DELAY} seconds before next API call...\")\n","        time.sleep(API_CALL_DELAY)\n","\n","if not new_long_comments_data:\n","    logging.warning(\"No new long comments were generated.\")\n","    if old_df.empty:\n","         logging.error(\"No existing data loaded and no new data generated. Exiting.\")\n","         print(\"\\nFailed to generate any new data and no existing data found. Cannot create merged file.\")\n","         \n","    else:\n","         # If only old data exists, maybe just save that? Or exit?\n","         # For now, let's proceed to save only the old data if new generation failed.\n","         logging.warning(\"Proceeding with only the previously loaded data.\")\n","         merged_df = old_df\n","else:\n","    logging.info(f\"Total new long comments generated: {len(new_long_comments_data)}\")\n","    new_df = pd.DataFrame(new_long_comments_data)\n","\n","    # Optional: Clean new data (remove duplicates within the new data)\n","    new_df.drop_duplicates(subset=['text', 'label'], inplace=True)\n","    logging.info(f\"{len(new_df)} unique new long comments generated.\")\n","\n","\n","    # --- Merge DataFrames ---\n","    logging.info(\"Merging existing data with newly generated long comments...\")\n","    df = pd.concat([old_df, new_df], ignore_index=True)\n","    logging.info(f\"Total records before final duplicate check: {len(df)}\")\n","\n","    # Final check for duplicates across the entire merged dataset\n","    initial_merged_rows = len(df)\n","    df.drop_duplicates(subset=['text', 'label'], inplace=True)\n","    duplicates_removed = initial_merged_rows - len(df)\n","    if duplicates_removed > 0:\n","        logging.info(f\"Removed {duplicates_removed} duplicate entries from the final merged dataset.\")\n","\n","# --- Save Merged DataFrame to CSV ---\n","if df.empty:\n","    logging.error(\"Merged dataset is empty. Nothing to save.\")\n","    print(\"\\nResulting dataset is empty. No file will be saved.\")\n","    \n","\n","logging.info(f\"Final merged dataset contains {len(df)} records.\")\n","try:\n","    df.to_csv(OUTPUT_CSV_FILE, index=False, encoding='utf-8')\n","    logging.info(f\"Merged dataset successfully saved to '{OUTPUT_CSV_FILE}'\")\n","    print(f\"\\nMerged dataset saved to {OUTPUT_CSV_FILE}\")\n","    print(f\"Total rows: {len(df)}\")\n","    print(\"\\nSample data (last 5 rows might include new long comments):\")\n","    print(df.tail()) # Show tail to potentially see new comments\n","    print(\"\\nLabel distribution (merged):\")\n","    print(df['label'].value_counts())\n","except Exception as e:\n","    logging.error(f\"Error saving merged DataFrame to CSV: {e}\")\n","    print(f\"\\nError saving the merged dataset to {OUTPUT_CSV_FILE}. Check permissions or disk space.\")\n","\n","logging.info(\"--- Dataset Generation Finished ---\")\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"a93bad2c","metadata":{"papermill":{"duration":0.002453,"end_time":"2025-04-26T09:52:13.123762","exception":false,"start_time":"2025-04-26T09:52:13.121309","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":7255304,"sourceId":11574013,"sourceType":"datasetVersion"}],"dockerImageVersionId":31012,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"papermill":{"default_parameters":{},"duration":51.03884,"end_time":"2025-04-26T09:52:15.849921","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-04-26T09:51:24.811081","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}